\section*{Conclusions}
\phantomsection
Data science is fresh evolving field that has a positive impact over more that a single economical area. The use cases of its applicability are so many that it resulted in many other narrow subfields. The whole philosophy of data science lies in extracting some value from the tremendous amounts of raw data. Data journalism is a surfacing domain of data science that aims to to facilitate the classic journalism by providing a set of tools which offer diverse way of visualization data under different formats. Such kind of tools targets journalists that can write quality stories. The distinguishing key between the classic and data journalism is that the later opens the doors to writing the most compelling stories. It can be used to connect dots and prove theories that can give as result meaningful statements backed up by viable arguments.

The outcome of the thesis is the project OpenMedia. It is a platform that aggregates online media sources from Republic of Moldova in order to offer basic tools for data visualization. From a big picture it looks very much like a data warehouse system. The only difference that the target and the data sources is unusual for the moldavian market. There still are no tools available which does a similar thing on the local level. Developing a software that doesn't yet exist on a market offers a lot of freedom, but at the same time is problematic because the needs of the potential customers are yet unknown. It might be that a joint work with a representative of journalism would have resulted into a more specific and reasonable product.

Building the application required many multi-step planning of the infrastructure. The problem encountered with collecting the data is that some media sources does not encode the article URL under a specific pattern that can be followed. Which means that some media sources are more easy to integrate and some not. A last resort solution would be to directly contact the representatives of media source and kindly for access of the data. Still there are many but and ifs in this situation.

Another major problem encountered while developing the platform is the natural language processing operations. Unfortunately, for the romanian language, there aren't any public available libraries that can be used for applying NLP operations. The only found solutions is using a web service provided by two sources, more specifically two universities from Romania. The problem is that using a web service for processing huge amount of textual takes a lot of time leaving no room for experiments. Another thing that the debugging process becomes more tedious. The NLP part of the applications relies heavily on these two sources. The whole project might be ruined in case the sources are not public anymore. Resulting that OpenMedia is not a robust application.

There are lots of ideas for further development of the project. In order to make them more flourishing it would be better establish a collaboration with a media representative. The first things that would be added are the basic registration, profile routine. Every user will have a personal query history which will allow to browse the previous results faster. Another important part is adding more visualization tools. In this case the media corespondent might give suggestions for building a more specific requirements. In the immediate future is planned to implement the trend detection feature. Another essential part is to integrate as many media channels as possible, it is crucial to offer a result from multiple sources. In a long run it is intended is to create emotional analysis upon articles. The complexity of such feature is highly increased hence a thorough research would be needed and the software should be very well tested.

A quintessential important part for the future development of OpenMedia is to remove the dependencies with the web services which helps with the NLP operations. The services are useful for the first phase of development but when it comes to building reliable applications it can not be afforded to rely on external tools. It might put the whole platform in jeopardy. Building a trustworthy NLP library would require a lot of time investment and research but should prove a useful in the long run.

Another thing would be to reconstruct the client side application from the perspective of creating a better user experience. It would also require a designers touch, which the application totally lacks. Also a lot of time will be invested for building the right tools for data visualization. Just displaying some results to the screen is not good enough if it doesn't communicate a message to the user. In the end the story behind the data is what matters.
\clearpage